[
  {
    "objectID": "handover.html",
    "href": "handover.html",
    "title": "PHU Data Specialist Instruction/Guidelines Handbook",
    "section": "",
    "text": "This handbook is dedicated for the next Data Specialist taking over the position within the Public Health Unit in the Global Programmes department at HQ. The book dives into each aspect of the position, showcasing step by step guidances on how to run the existing tools and how to maintain them.\nI will try my best to be as detailed as possible, but do know that other data/technical people will also have answers to all your questions.",
    "crumbs": [
      "PHU Data Specialist Instruction/Guidelines Handbook"
    ]
  },
  {
    "objectID": "handover.html#impactr4phu",
    "href": "handover.html#impactr4phu",
    "title": "PHU Data Specialist Instruction/Guidelines Handbook",
    "section": "impactR4PHU",
    "text": "impactR4PHU\nhealthyR, a tool built by Saeed Rahman (current PHU Unit Manager), has been a crucial tool for checking, cleaning and analysing the data of almost all the outcome indicators of the different sectors of Public Health (Health/Nutrition/Food Security & Livelihoods - FSL/WASH).\nimpactR4PHU followed the same original content structure of heathyR, but addressed some of the feedback from the users, as well as some other bugs/issues. The package also introduced project templates for fast implementations of the processes.\nThis package is following a Test-Driven Development where unit testing, programming, and refactoring of the source code is addapted during development stages.\n\nContent\nHere is a quick dissection of the GitHub Repo, but please do check the READ ME Section for a better description of each component.\n\nmain branch\n\nR Folder\nThis folder includes all the functions that are used by the Public Health Unit for creating, adding, checking, and ploting data within different processes. Almost all functions have a test unit script using the testthat package. The tests can be access through the testing branch. Some of the functions are helpers functions and do not include testers.\nAll functions are built in a way that can be piped within the dplyr system of piping.\nOnce you have checked all the functions, you might ask yourself a question.\n\n“Where are the functions related to Health and WASH?”\n\nThey exist, but not in this package. At Impact, we love to share tasks sometimes, mainly when it is used for specific purposes in other units. You will be able to find these respective functions in the humind package. The humind package is built to address main calculations for indicators collected through the MSNA (Multi-Sectoral Needs Assessment). To know more about this assessment or the package, please reach out to the HPPU Unit colleagues.\nAll functions are well documented using Roxygen, and some funcitons are running some examples using dummy data included in the package.\n\n\ndata Folder\nThis folder includes different dummy datasets used within the examples inside the functions, but also within the test units.\n\n\ninst Folder\nThis folder includes different project templates:\n\nFSL: Food Security and Livelihoods.\nIYCF: Infant Youth Consumption Food TO CHECK\nMortality\nIPHRA: Integrated Public Health Rapid Assessment\nPublic Health integrated tables\n\nYou might ask yourself another question here.\n\nWhy do we have templates if there are already functions?\n\nGood question!! But here is the answer.\nImpact’s field missions are widely different when it come to data resources, capacity, and knowledge. Some missions do not even have data officers. So these templates exists to make the life of users with little knowledge of R easier and faster. They only need to set up R and R Studio on their machines, and run the respective scripts.\nThese project templates can easily be accessed through the “New Project” button in R Studio after installing the Package\n\ndevtools::install_github(“impact-initiatives/impactR4PHU”)\n\nThe scripts interacts with the users through inputs system. Inputs here are very important to make sure that the scripts are outputing the correct intentions.\nPlease make sure to refer back to the respective specialists within the Public Health Unit so they can help you with what to select what when it comes to running the scripts.\n\nMortality: Noortje Gerritzma\nFSL: Olivia Falkowitz\nIYCF: Martin\nIPHRA: PH team\nPH Integrated Tables: PH team or Olivia.\n\nMortality, FSL, and IYCF have 3 templates:\n\nPlausibility and Quality Reports\nCleaning\nDescriptive analysis.\n\nIPHRA have 2 templates:\n\nCleaning\nAnalysis\n\nPH integrated Tables have only 1 template.\nAll the details needed are explained in the READ ME sections of the github page.\n\n\n\ntesting branch\n\ntests Folder\nUsing the testthat package, and followint the TDD method, all functions have been tested following the good and bad path to make sure that they are outputing the expected results. Please do ensure to build tests always with every added functions, and feel free to add tests to existing functions.\n\n\n\n\nMaintenance\nIf changes, improvements, enhancements, add-ons are required to the package, please use the following process to ensure a smooth merging to the main branch.\nFirst, clone the main package to your local machine and create a new branch for your work. If functions are created/ammended, please make sure to checkout to the testing branch and do the necessary work there to keep the package trusted and correctly functioning.\nOnce done, go ahead commit and push your changes to your respective branch, and open a pull requests.\nOnce you create the pull request, some Github Actions will run in teh background to ensure that the package is functional and installable in different operating systems and the coverage test badge is updated. If all the actions pass the tests, I set a requirement here to have a review and validation by another person. However, as a solo data person in the unit, this can be bypassed and merge can be confirmed.\nGithub will again run another test of the Actions and pass a green badge to the R CMD Check.\n\nThe job is not yet done !!\n\nAs all the templates are using there own specific renv environment that also include the impactR4PHU github package, all these renv of the different templates should be updated to the newest version of the package.\nI created a python script that update them automatically instead of accessing them one by one. Here is a link to the python script link (ADD THE FILE HERE)\nOnce the script is done, please go again to your local branch where the new changes have been made and you will realise that all renv.lock files have now updated and require a new commit, push and pull for github. I know this is a bit of an annoying process, please go ahead and change it to your convenience.\n\n\nRequirements\n\nPlease inform users to always re-install the package so they can access the latest version, especially if you are constantly enhancing/improving/changing something within the package. This is required because of the renv.locks that includes all newest packages requirements.\nEach template have a renv::update() function in the beginning which is responsible of updating the relevant packages to the latest requirements for the dependencies. However, R sometimes love to be hard and try to break everything. I realized this after receiving some weird “make error” from the field. Kindly keep an eye on that.\n\n\n\nNext Steps Suggestions\nAs the rotation within Impact is relatively high, you should consider having regular refreshers for missions/HQ Global Programs (GP) and Research Department (RDD) on the usage of the package and mainly the templates.\n\n“Why GP and RDD included?”\n\nBecause, they do use the plausibility and quality report, mainly FSL, to check the data that is sent from missions for validation to HQ.\n\nBetter way than R templates?\n\nMy original plan was to create one whole system (software) that compile all the processes and be even more user friendly then still running R codes. However, this takes so much time to implement and we didn’t have the time. So maybe this is something that can be done as a project.\n\n\nKnowledge requirements to run/maintain/enhance\n\nR: Advanced\nGit and Github Actions: Advanced\nTest-Driven Development: Advanced\nKobo: Intermediate\nPython: Beginner",
    "crumbs": [
      "PHU Data Specialist Instruction/Guidelines Handbook"
    ]
  },
  {
    "objectID": "handover.html#rlc-random-location-cluster-sampling-scripts",
    "href": "handover.html#rlc-random-location-cluster-sampling-scripts",
    "title": "PHU Data Specialist Instruction/Guidelines Handbook",
    "section": "RLC (Random Location Cluster) Sampling Scripts",
    "text": "RLC (Random Location Cluster) Sampling Scripts\nThis Github Repo is LINK is dedicated for checking the quality of the data collection using the Random Location Cluster sampling or RLC for short as well as producing the weights for the different clusters.\nTo understand more about RLC, please check the presentations and the registrations available in the handover folder.\nIn a nutshell, RLC is a sampling method that requires to define a populated area, and randomly select N amount of GPS locations within this area. Once defined, the 3 nearest neighbouring HH to the defined GPS location are assessed.\nI created a Kobo tool called REACH GEO RAND that allows you to go to the field and trace the areas of interested and the tool will automatically generate N random points within this area with their respective UNIQUE IDs. Please check the presentation of the tool in the handover folder.\nThe output is an html report including:\n\nID MATCHING: Check Cluster_ID between sampling and rlc data are matching\nClusters inside Area: Check Clusters are inside the sampling area (50m threshold)\nClusters follow RLC sampling: Check assessed clusters are random and follow the sampling (50m threshold)\nHHs inside sampling area: Check assessed HHs are inside the sampling are (50m threshold)\nDistance HHs to clusters: Check the distance between the assessed HHs and the sampled cluster points (50m threshold)\nDuplicated clusters/HHs: Check duplication between clusters and check if clusters share same HHs.\nHousehold Density: Calculate HH Density & Cluster Weights\nIDW: Spatial Interpolation using Inverse Distance Weighing (IDW)\nEstimation of Population: Estimate Population of Sampled Area. (Under Revision)\n\nAs well as an Excel file that includes the weights.\n\nRequirements\nThis script are built using the REACH GEO RAND output data that consists of:\n\nSheet including the traced areas\nSheet including the randomly generated points\n\nAs well as your assessment data following the RLC sampling methodology that includes:\n\nUNIQUE IDs of the randomly generated points\nGPS locations of the randomly generated points\nGPS locations of the 3 assessed HHs\nNumber of individuals inside each HH\n\n\n\nContent\n\nmain branch\n\nresources folder\nThis folder includes all the images/logos/local R packages needed to run the script in general.\n\n\nsrc folder\nThis folder includes multiple R scripts:\n\ninit.R: This script is used to install and load all the packages needed for this scripts.\nrlc_quality_check.R & rlc_quality_check_fast_track.R: These are scripts that contains all the functions needed to perform the quality checks and create the outputs.\n\nAlso it includes a utils folder which includes all the other utility functions needed for cleaning/analysing/reporting.\n\n\nmain folder\nThis folder includes multiple R, Rmd, and batch files. Below is the explanation of each:\nFAST TRACK\n\nfast_track.R:\n\n\n\n\n\nMaintenance\n\n\nNext Steps Suggestions",
    "crumbs": [
      "PHU Data Specialist Instruction/Guidelines Handbook"
    ]
  },
  {
    "objectID": "handover.html#remote-mortality-studies-in-drc",
    "href": "handover.html#remote-mortality-studies-in-drc",
    "title": "PHU Data Specialist Instruction/Guidelines Handbook",
    "section": "Remote Mortality Studies in DRC",
    "text": "Remote Mortality Studies in DRC",
    "crumbs": [
      "PHU Data Specialist Instruction/Guidelines Handbook"
    ]
  }
]